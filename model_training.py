# -*- coding: utf-8 -*-
"""model_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zpwP7q0bXjl-FsNWEQ9rkhyqJgrFG7h2
"""

# model_training.py
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import pickle

# -----------------------------
# 1. Load dataset
# -----------------------------
df = pd.read_csv("crime_dataset.csv")

# Drop unnecessary ID/code columns
df = df.drop(columns=['id', 'state_code', 'district_code'], errors='ignore')

# -----------------------------
# 2. Prepare features and target
# -----------------------------
# Select all crime columns (numeric)
crime_columns = df.columns[7:]  # adjust if columns differ

# Create target label: crime type with maximum count
df['top_crime'] = df[crime_columns].idxmax(axis=1)

# Define X and y
X = df[['year', 'state_name', 'district_name']]
y = df['top_crime']

# -----------------------------
# 3. Encode categorical columns
# -----------------------------
le_state = LabelEncoder()
le_district = LabelEncoder()
le_crime = LabelEncoder()

X['state_name'] = le_state.fit_transform(X['state_name'])
X['district_name'] = le_district.fit_transform(X['district_name'])
y_encoded = le_crime.fit_transform(y)

# -----------------------------
# 4. Train-test split
# -----------------------------
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# -----------------------------
# 5. Train two models
# -----------------------------
# Model 1: Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
rf_preds = rf.predict(X_test)
rf_acc = accuracy_score(y_test, rf_preds)

# Model 2: Logistic Regression
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
lr_preds = lr.predict(X_test)
lr_acc = accuracy_score(y_test, lr_preds)

# -----------------------------
# 6. Compare and print results
# -----------------------------
print("ðŸ”¹ Random Forest Accuracy:", rf_acc)
print("ðŸ”¹ Logistic Regression Accuracy:", lr_acc)

if rf_acc > lr_acc:
    best_model = rf
    print("\nâœ… Best Model: Random Forest")
else:
    best_model = lr
    print("\nâœ… Best Model: Logistic Regression")

# -----------------------------
# 7. Save the best model + encoders
# -----------------------------
pickle.dump(best_model, open("best_model.pkl", "wb"))
pickle.dump(le_state, open("state_encoder.pkl", "wb"))
pickle.dump(le_district, open("district_encoder.pkl", "wb"))
pickle.dump(le_crime, open("crime_encoder.pkl", "wb"))

print("\nâœ… Model and encoders saved successfully!")